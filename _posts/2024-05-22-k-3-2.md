---
title: "[Kubernetes]-도커&쿠버네티스 3일차(2)"
excerpt: "쿠버네티스 Controller"

categories:
  - Kubernetes
tags:
  - [kubernetes, docker]

permalink: /kubernetes/k-3-2/

toc: true
toc_sticky: true

date: 2024-05-22
last_modified_at: 2024-05-22
---
# 쿠버네티스 3일차 -2 

### 쿠버네티스 사전작업

 - 도커파일 생성
 > docker build -t hwlim78/web-site:food -f Dockerfile-food ./

 - 도커파일 도커허브에 푸쉬
 > docker push hwlim78/web-site:food


### 1. 쿠머네티트스 설치

- Kubernetes 클러스터

- all nodes

```
timedatectl set-timezone Asia/Seoul
setenforce 0
sed -i 's/^SELINUX=enforcing$/SELINUX=disabled/' /etc/selinux/config
tee /etc/modules-load.d/containerd.conf <<EOF
overlay
br_netfilter
EOF

modprobe overlay
modprobe br_netfilter

tee /etc/sysctl.d/kubernetes.conf<<EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF

sysctl --system  //커널 설정 수정 시 적용
yum install -y yum-utils device-mapper-persistent-data lvm2
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo  //최신의 컨테이너 런타임을 설치하기 위한 레포지토리
yum install -y containerd.io bash-completion

mkdir -p /etc/containerd
containerd config default > /etc/containerd/config.toml

systemctl restart containerd
systemctl enable --now containerd

cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml.key
exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni
EOF

yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
systemctl enable --now kubelet
```



- Master Node

```
kubeadm init --apiserver-advertise-address=10.178.0.7 --pod-network-cidr=10.244.0.0/16
mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config
kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml  // pod간 통신을 위한 CNI 설치
kubectl get pods --all-namespaces
yum install -y bash-completion                           // 자동 완성 기능
source <(kubectl completion bash)                        // 명령어 적용
echo "source <(kubectl completion bash)" >> ~/.bashrc    // 호스트가 재부팅 후에도 자동완성기능 재실행
exit
```

- Worker Node

```
kubeadm join 10.178.0.7:6443 --token q1474c.vkhplse7meteo9i3 \
        --discovery-token-ca-cert-hash sha256:0d5628c570d2d13d7309611f78fd571365e9bcbcfd64db6db1990e1ae5c1ade1

kubectl get nodes // 조인상태 확인
```

### 2. 쿠머네티스 클러스터 구성 

- 컴포넌트 구성요소(POD로 구성)

  - kubectl을 통해 yaml 파일로 설정 및 명령

  - Control manager : 가장 많은 작업 리소스 컴포넌트
  ```
    1) 노드 컨트롤러 : 노드 다운 때 통지 및 대응
      -> public IP, DNS 매핑, LB연동 등 용이
    2) 레플리케이션 컨트롤러 : pod 갯수 생성 및 유지
    3) 엔드포인트 컨트롤러 : 네트워크 서비스와 POD를 연결지시(kube-proxy : 연결수행)
    4) 서비스 어카운트 & 토큰 컨트롤러 : 접근통제 및 계정보안관리 
  ``` 

  - ETCD(key-value 스토어) 클러스터의 pod 상태 저장소(DB)

  - API-server : 마스터 노드의 manager 역할

  - 스케쥴러 : 컨테이너의 POD를 적절하게 워커노드에 리소스를 기준으로 배치 및 할당하는 컴포넌트

  - CCM (cloud control manager) : 퍼블릭 클라우드 환경에서 사용(aks, eks, aks)
    - 오토스케일링, 자동백업 등 가용성이 이점

  - Kube-Proxy : 외부에서 접속하는 방법 제공, 노드 or 클러스터 IP에 네트워크 구현부
    - proxy 는 노드별로 구성


- 워커노드 구성요소
 - kubelet : CRI(container runtime interface) 제어
   - 실제 컨테이너를 이용해 POD를 생성하고 실행하는 Agent

 - CNI : 각 워커노드 or POD 간 네트워크(overlay) 연결
   - 예) calico, nuage, cisco, flannel 등
 
 - CRI : 컨테이너 도구
   - 예: docker, containerd, CRI-O)
 
 - kube-proxy : enduser가 노드에 연결하는 기능
 
 - data-plane 연할
 
 - 워커노드는 API 서버에 구독을 통해 정보를 얻어서 실행을 함
 
 - API 서버로부터 지시를 받는 방식이 아님



   

#### Kubernetes 기본 명령어

```
mkdir workspace && cd $_
kubectl [명령어] [유형] [이름] [옵션]
kubectl get node
kubectl run nginx-pod --image=nginx pending > ContainerCreating > Running
kubectl get pod
kubectl get pods -n kube-system       // 네임스페이스 상태, -n(namespace)
kubectl get service
kubectl expose pod nginx-pod --name clusterip --type=ClusterIP --port 80
kubectl expose pod nginx-pod --name nodeport --type=NodePort --port 80
kubectl expose pod nginx-pod --name loadbalancer --type=LoadBalancer --external-ip 192.168.0.29 --port 80
kubectl get pod
kubectl get service
kubectl exec -it nginx-pod -- bash
kubectl cp html nginx-pod:/usr/share/nginx
kubectl get all
kubectl delete svc --all
kubectl delete pod nginx-pod
kubectl delete pod,svc --all
kubectl delete pods <pod> --grace-period=0 --force pod
kubectl options
kubectl api-resources
kubectl get nodes -o wide
kubectl get nodes -o wide --no-headers
kubectl get nodes -o wide --no-headers | awk '{print $6}'
kubectl create deployment nginx-app --replicas=2 --image=nginx
kubectl get deployments.apps
kubectl get replicasets.apps
kubectl get pods
kubectl expose deployment nginx-app --name clusterip-app --type=ClusterIP --port 80
kubectl expose deployment nginx-app --name nodeport-app --type=NodePort --port 80
kubectl expose deployment nginx-app --name loadbalancer-app --type=LoadBalancer --external-ip 192.168.0.29 --port 80
kubectl get service
kubectl scale deployment nginx-app --replicas=4
kubectl get pods
kubectl scale deployment nginx-app --replicas=2
kubectl get pods
kubectl delete deployments.apps nginx-app
kubectl delete service --all
```

- Kubernetes 네임스페이스

```
kubectl get namespaces
kubectl config get-contexts kubernetes-admin@kubernetes
kubectl config set-context kubernetes-admin@kubernetes --namespace=kube-system
kubectl config get-contexts kubernetes-admin@kubernetes
kubectl config set-context kubernetes-admin@kubernetes --namespace=default
kubectl create namespace test-namespace
kubectl get namespace
kubectl config set-context kubernetes-admin@kubernetes --namespace=test-namespace
kubectl config set-context kubernetes-admin@kubernetes --namespace=default
```

#### Kubernetes 파드, 디플로이먼트, 서비스


- Pod
```
vi nginx-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
  labels:
    app: nginx-pod
spec:
  containers:
  - name: nginx-pod-container
    image: nginx

kubectl apply -f nginx-pod.yaml
kubectl get pod -o wide
kubectl describe pod nginx-pod

vi clusterip-pod.yaml
apiVersion: v1
kind: Service
metadata:
  name: clusterip-pod
spec:
  type: ClusterIP
  selector:
    app: nginx-pod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80

kubectl apply -f clusterip-pod.yaml
kubectl get svc -o wide
kubectl describe svc clusterip-pod
kubectl edit svc clusterip-pod

vi nodeport-pod.yaml
apiVersion: v1
kind: Service
metadata:
  name: nodeport-pod
spec:
  type: NodePort
  selector:
    app: nginx-pod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
    nodePort: 30080

kubectl apply -f nodeport-pod.yaml
kubectl get svc -o wide
kubectl describe svc nodeport-pod
kubectl edit svc nodeport-pod

vi loadbalancer-pod.yaml
apiVersion: v1
kind: Service
metadata:
  name: loadbalancer-pod
spec:
  type: LoadBalancer
  externalIPs:
  - 192.168.1.188
  - 192.168.1.211
  - 192.168.1.216
  selector:
    app: nginx-pod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80

kubectl apply -f loadbalancer-pod.yaml
kubectl get svc -o wide
kubectl describe svc loadbalancer-pod
kubectl edit svc loadbalancer-pod
```


- Deployment

```
vi deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx-deployment

  template:
    metadata:
      name: nginx-deployment
      labels:
        app: nginx-deployment
    spec:
      containers:
      - name: nginx-deployment-container
        image: nginx
        ports:
        - containerPort: 80

kubectl apply -f deployment.yaml
kubectl get deployments.apps -o wide
kubectl describe deployments.apps nginx-deployment
kubectl edit deployments.apps nginx-deployment

vi clusterip-deployment.yaml 클러스터아이피 야믈
apiVersion: v1
kind: Service
metadata:
  name: clusterip-deployment
spec:
  type: ClusterIP
  selector:
    app: nginx-deployment
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80

kubectl apply -f clusterip-deployment.yaml
kubectl get svc -o wide
kubectl describe svc clusterip-deployment
kubectl edit svc clusterip-deployment

vi nodeport-deployment.yaml 노드포트 야믈
apiVersion: v1
kind: Service
metadata:
  name: nodeport-deployment
spec:
  type: NodePort
  selector:
    app: nginx-deployment
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
    nodePort: 30080

kubectl apply -f nodeport-deployment.yaml
kubectl get svc -o wide
kubectl describe svc nodeport-deployment
kubectl edit svc nodeport-deployment

vi loadbalancer-deployment.yaml 로드밸런서 야믈
apiVersion: v1
kind: Service
metadata:
  name: loadbalancer-deployment
spec:
  type: LoadBalancer
  externalIPs:
  - 192.168.0.143
  selector:
    app: nginx-deployment
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80

kubectl apply -f loadbalancer-deployment.yaml
kubectl get svc -o wide
kubectl describe svc loadbalancer-deployment
kubectl edit svc loadbalancer-deployment

kubectl get all
kubectl delete pod,svc --all
kubectl delete replicaset,svc --all
kubectl delete deployment,svc --all
```



- Kubernetes 컨피그맵, 시크릿

vi configmap-dev.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: config-dev
  namespace: default
data:
  DB_URL: localhost
  DB_USER: myuser
  DB_PASS: mypass
  DEBUG_INFO: debug

kubectl describe configmaps config-dev

vi deployment-config01.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: configapp
  labels:
    app: configapp
spec:
  replicas: 1
  selector:
    matchLabels:
      app: configapp

  template:
    metadata:
      labels:
        app: configapp
    spec:
      containers:
      - name: testapp
        image: nginx
        ports:
        - containerPort: 8080
        env:
        - name: DEBUG_LEVEL
          valueFrom:
            configMapKeyRef:
              name: config-dev
              key: DEBUG_INFO

apiVersion: v1
kind: Service
metadata:
  labels:
    app: configapp
  name: configapp-svc
  namespace: default
spec:
  type: NodePort
  ports:
  - nodePort: 30800
    port: 8080
    protocol: TCP
    targetPort: 80
  selector:
    app: configapp

kubectl exec -it configapp-64d4554b68-v55g5 -- bash

vi configmap-wordpress.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: config-wordpress
  namespace: default
data:
  MYSQL_ROOT_HOST: '%'
  MYSQL_DATABASE: wordpress

kubectl apply -f configmap-wordpress.yaml
kubectl describe configmaps config-wordpress

vi secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-secret
stringData:
  MYSQL_ROOT_PASSWORD: mode1752
  MYSQL_USER: wpuser
  MYSQL_PASSWORD: wppass

kubectl apply -f secret.yaml
kubectl describe secrets my-secret

vi mysql-pod-svc.yaml
apiVersion: v1
kind: Pod
metadata:
  name: mysql-pod
  labels:
    app: mysql-pod
spec:
  containers:
  - name: mysql-container
    image: mysql:5.7
    envFrom:
    - configMapRef:
        name: config-wordpress
    - secretRef:
        name: my-secret
    ports:
    - containerPort: 3306
---
apiVersion: v1
kind: Service
metadata:
  name: mysql-svc
spec:
  type: ClusterIP
  selector:
    app: mysql-pod
  ports:
  - protocol: TCP
    port: 3306
    targetPort: 3306

vi wordpress-pod-svc.yaml
apiVersion: v1
kind: Pod
metadata:
  name: wordpress-pod
  labels:
    app: wordpress-pod
spec:
  containers:
  - name: wordpress-container
    image: wordpress
    env:
    - name: WORDPRESS_DB_HOST
      value: mysql-svc
    - name: WORDPRESS_DB_USER
      valueFrom:
        secretKeyRef:
          name: my-secret
          key: MYSQL_USER
    - name: WORDPRESS_DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: my-secret
          key: MYSQL_PASSWORD
    - name: WORDPRESS_DB_NAME
      valueFrom:
        configMapKeyRef:
          name: config-wordpress
          key: MYSQL_DATABASE
    ports:
    - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: wordpress-svc
spec:
  type: LoadBalancer
  externalIPs:
  - 192.168.0.25
  selector:
    app: wordpress-pod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80

vi mysql-deploy-svc.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql-deploy
  labels:
    app: mysql-deploy
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mysql-deploy
  template:
    metadata:
      labels:
        app: mysql-deploy
    spec:
      containers:
      - name: mysql-container
        image: mysql:5.7
        envFrom:
        - configMapRef:
            name: config-wordpress
        ports:
        - containerPort: 3306
---
apiVersion: v1
kind: Service
metadata:
  name: mysql-svc
spec:
  type: ClusterIP
  selector:
    app: mysql-deploy
  ports:
  - protocol: TCP
    port: 3306
    targetPort: 3306

vi wordpress-deploy-svc.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wordpress-deploy
  labels:
    app: wordpress-deploy
spec:
  replicas: 1
  selector:
    matchLabels:
      app: wordpress-deploy
  template:
    metadata:
      labels:
        app: wordpress-deploy
    spec:
      containers:
      - name: wordpress-container
        image: wordpress
        volumeMounts:
        - mountPath: /var/www/html
          name: hostpath-vol
        env:
        - name: WORDPRESS_DB_HOST
          value: mysql-svc:3306
        - name: WORDPRESS_DB_USER
          valueFrom:
            configMapKeyRef:
              name: config-wordpress
              key: MYSQL_USER
        - name: WORDPRESS_DB_PASSWORD
          valueFrom:
            configMapKeyRef:
              name: config-wordpress
              key: MYSQL_PASSWORD
        - name: WORDPRESS_DB_NAME
          valueFrom:
            configMapKeyRef:
              name: config-wordpress
              key: MYSQL_DATABASE
        ports:
        - containerPort: 80
      volumes:
      - name: hostpath-vol
        hostPath:
          path: /tmp
          type: Directory
---
apiVersion: v1
kind: Service
metadata:
  name: wordpress-svc
spec:
  type: LoadBalancer
  selector:
    app: wordpress-deploy
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80

--- Kubernetes 볼륨
- pv/pvc
pv-pvc-pod.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: task-pv-volume
  labels:
    type: local
spec:
  storageClassName: manual
  capacity:
    storage: 10Mi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/mnt/data"
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: task-pv-claim
spec:
  storageClassName: manual
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Mi
  selector:
    matchLabels:
      type: local
---
apiVersion: v1
kind: Pod
metadata:
  name: task-pv-pod
  labels:
    app: task-pv-pod
spec:
  volumes:
    - name: task-pv-storage
      persistentVolumeClaim:
        claimName: task-pv-claim
  containers:
    - name: task-pv-container
      image: nginx
      ports:
        - containerPort: 80
          name: "http-server"
      volumeMounts:
        - mountPath: "/usr/share/nginx/html"
          name: task-pv-storage

* rm -rf /mnt/data
* kubectl apply -f .
* echo "HELLO" > /mnt/data/index.html
* kubectl delete pod task-pv-pod
* kubectl delete pvc task-pv-claim
* Retain 동일한 스토리지 자산을 재사용하려는 경우, 동일한 스토리지 자산 정의로 새 퍼시스턴트볼륨을 생성한다.

- nfs
yum install -y nfs-utils.x86_64
mkdir /nfs_shared
chmod 777 /nfs_shared/
echo '/nfs_shared 192.168.0.0/21(rw,sync,no_root_squash)' >> /etc/exports
systemctl enable --now nfs
vi nfs-pv.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-pv
spec:
  capacity:
    storage: 100Mi
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  nfs:
    server: 192.168.0.184
    path: /nfs_shared

kubectl apply -f nfs-pv.yaml
kubectl get pv
vi nfs-pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-pvc
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 10Mi

kubectl apply -f nfs-pvc.yaml
kubectl get pvc
kubectl get pv
vi nfs-pvc-deploy.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfs-pvc-deploy
spec:
  replicas: 4
  selector:
    matchLabels:
      app: nfs-pvc-deploy

  template:
    metadata:
      labels:
        app: nfs-pvc-deploy
    spec:
      containers:
      - name: nginx
        image: nginx
        volumeMounts:
        - name: nfs-vol
          mountPath: /usr/share/nginx/html
      volumes:
      - name: nfs-vol
        persistentVolumeClaim:
          claimName: nfs-pvc

kubectl apply -f nfs-pvc-deploy.yaml
kubectl get pod
kubectl exec -it nfs-pvc-deploy-76bf944dd5-6j9gf -- /bin/bash
kubectl expose deployment nfs-pvc-deploy --type=LoadBalancer --name=nfs-pvc-deploy-svc1 --external-ip 192.168.0.192 --port=80

--- Kubernetes 스테이트풀셋, 잡
- statefulset
cd ~
mkdir statefulset && cd $_
cat <<EOF > pv2.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: www-web-2
spec:
  capacity:
    storage: 1Gi
  volumeMode: Filesystem
  accessModes:
  - ReadWriteOnce
  storageClassName: manual
  persistentVolumeReclaimPolicy: Delete
  hostPath:
    path: /tmp
EOF

cat <<EOF > sample-statefulset.yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  ports:
  - port: 80
    name: web
  clusterIP: None
  selector:
    app: nginx
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: web
spec:
  selector:
    matchLabels:
      app: nginx
  serviceName: "nginx" 헤드레스 서비스를 지정한다.
  replicas: 3 by default is 1
  template:
    metadata:
      labels:
        app: nginx
    spec:
      terminationGracePeriodSeconds: 10 강제 종료까지 대기하는 시간
      containers:
      - name: nginx
        image: k8s.gcr.io/nginx-slim:0.8
        ports:
        - containerPort: 80
          name: web
        volumeMounts:
        - name: www
          mountPath: /usr/share/nginx/html
  volumeClaimTemplates: PVC 설정을 저장하는 부분
  - metadata:
      name: www
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: "standard"
      resources:
        requests:
          storage: 1Gi
EOF

kubectl apply -f sample-statefulset.yaml

cat <<EOF > loadbalancer-kiali.yaml
apiVersion: v1
kind: Service
metadata:
  name: loadbalancer-service-kiali
spec:
  type: LoadBalancer
 externalIPs:
 - 10.178.0.25
  selector:
    app: kiali
  ports:
  - protocol: TCP
    port: 20001
    targetPort: 20001
  - protocol: TCP
    port: 9090
    targetPort: 9090
EOF

kubectl apply -f loadbalancer-pod.yaml
kubectl get svc -o wide
kubectl describe svc loadbalancer-service-pod

- job
cd ~
mkdir job_cronjob && cd $_
cat <<EOF > batch-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: batch-job
spec:
  template:
    metadata:
      labels:
        app: batch-job
    spec:
      restartPolicy: OnFailure
      containers:
      - name: main
        image: luksa/batch-job
EOF

kubectl apply -f batch-job.yaml
kubectl get jobs.batch -w
kubectl logs batch-job-7lpkp

잡에서 여러 파드 인스턴스 실행하기(순차적으로 잡 파드 실행하기)
cat <<EOF > multi-completion-batch-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: multi-completion-batch-job
spec:
  completions: 5
  template:
    metadata:
      labels:
        app: batch-job
    spec:
      restartPolicy: OnFailure
      containers:
      - name: main
        image: luksa/batch-job
EOF

kubectl apply -f multi-completion-batch-job.yaml
kubectl get jobs.batch -w
kubectl get po
NAME                               READY   STATUS      RESTARTS   AGE
batch-job-7lpkp                    0/1     Completed   0          28m
multi-completion-batch-job-4zng9   0/1     Completed   0          6m52s
multi-completion-batch-job-69zmr   0/1     Completed   0          2m40s
multi-completion-batch-job-cdckq   0/1     Completed   0          11m
multi-completion-batch-job-mhqw2   0/1     Completed   0          4m46s
multi-completion-batch-job-s6rls   0/1     Completed   0          9m1s

cat <<EOF > multi-completion-parallel-batch-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: multi-completion-batch-job
spec:
  completions: 5
  parallelism: 2
  template:
    metadata:
      labels:
        app: batch-job
    spec:
      restartPolicy: OnFailure
      containers:
      - name: main
        image: luksa/batch-job
EOF

kubectl apply -f multi-completion-parallel-batch-job.yaml
kubectl get jobs.batch -w
kubectl get po
NAME                               READY   STATUS      RESTARTS   AGE
batch-job-7lpkp                    0/1     Completed   0          38m
multi-completion-batch-job-49cnm   1/1     Running     0          28s
multi-completion-batch-job-8qvkb   1/1     Running     0          28s
multi-completion-batch-job-cxhtd   0/1     Completed   0          2m34s
multi-completion-batch-job-k7wzb   0/1     Completed   0          2m34s

잡을 주기적으로 또는 한 번 실행되도록 스케줄링하기(크론잡)
cat <<EOF > cronjob.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: batch-job-every-fifteen-minutes
spec:
  schedule: "0,15,30,45 * * * *" 15분 마다 실행
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: periodic-batch-job
        spec:
          restartPolicy: OnFailure
          containers:
          - name: main
            image: luksa/batch-job
EOF

kubectl apply -f cronjob.yaml
kubectl get cronjobs.batch -w
kubectl get po

--- Kubernetes 디플로이먼트 버전 관리
- Deployment 롤링 업데이트 제어

kubectl set image deployment.apps/nginx-deployment nginx-deployment-container=halilinux/web-site:v1.0
kubectl get all
kubectl rollout history deployment nginx-deployment
kubectl rollout history deployment nginx-deployment --revision=2 리비전2 상세보기
kubectl rollout undo deployment nginx-deployment 롤백(전 단계로 복원)
kubectl get all
kubectl rollout history deployment nginx-deployment
kubectl rollout history deployment nginx-deployment --revision=3 리비전3 상세보기
kubectl rollout undo deployment nginx-deployment --to-revision=2 리비전2로 복원

--- Kubernetes 데몬셋
cd ~
mkdir daemonset && cd $_
cat <<EOF > ssd-monitor-daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: ssd-monitor
spec:
  selector:
    matchLabels:
      app: ssd-monitor
  template:
    metadata:
      labels:
        app: ssd-monitor
    spec:
      nodeSelector:
        disk: ssd
      containers:
      - name: main
        image: luksa/ssd-monitor
EOF

kubectl apply -f ssd-monitor-daemonset.yaml
kubectl get ds
kubectl get po -o wide
kubectl get nodes --show-labels
kubectl label nodes worker1 worker2 disk=ssd
kubectl get ds
kubectl get po
kubectl logs pods/ssd-monitor-6bhtv

--- Kubernetes 헬름
- helm 설치 및 기본 명령어
curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
chmod 700 get_helm.sh
./get_helm.sh
echo 'source <(helm completion bash)' >>~/.bashrc
helm repo add kiamol https://kiamol.net
helm repo update
helm search repo vweb --versions
helm show values kiamol/vweb --version 1.0.0
helm install --set servicePort=8010 --set replicaCount=2 ch10-vweb kiamol/vweb --version 1.0.0
helm ls
kubectl describe deployments.apps ch10-vweb
kubectl get deployments.apps -l app.kubernetes.io/instance=ch10-vweb
helm upgrade --set servicePort=8010 --set replicaCount=4 ch10-vweb kiamol/vweb --version 1.0.0
kubectl get rs
kubectl get svc
kubectl edit svc ch10-vweb
spec:
  externalIPs:
  - 172.16.0.150

- helm 패키징
git clone https://github.com/johnlee0405/kiamol.git
cd kiamol/ch10
helm lint web-ping
helm install wp1 web-ping/
helm ls
helm show values web-ping
helm install --set targetUrl=kiamol.net wp2 web-ping
helm repo add stable https://charts.helm.sh/stable
helm install --set service.type=LoadBalancer --set service.externalPort=8008 --set env.open.DISABLE_API=false repo stable/chartmuseum --version 2.13.0
kubectl edit svc repo-chartmuseum
spec:
  externalIPs:
  - 172.16.0.151

helm repo add local http://172.16.0.151:8008
helm package web-site
curl --data-binary "@web-site-0.2.0.tgz" http://172.16.0.151:8008/api/charts
curl http://172.16.0.151:8008/index.yaml
helm repo update
helm search repo web-site
helm search repo local
cat web-ping-values.yaml
helm install -f web-ping-values.yaml wp3 local/web-ping
helm install ws local/web-site
kubectl get pod -l app=web-ping -o custom-columns='NAME:.metadata.name,ENV:.spec.containers[0].env[*].value'

helm ls -q
helm show values kiamol/vweb --version 2.0.0
helm install --set servicePort=8020 --set replicaCount=1 --set serviceType=ClusterIP ch10-vweb-v2 kiamol/vweb --version 2.0.0
helm uninstall ch10-vweb-v2
helm get values ch10-vweb
helm upgrade --reuse-values --atomic ch10-vweb kiamol/vweb --version 2.0.0
helm history ch10-vweb
helm get values ch10-vweb --revision 2
helm rollback ch10-vweb 2
helm history ch10-vweb --max 2 -o yaml

--- Kubernetes 플루언트디, 일래스틱서치
- fluentd
ls /var/log/containers/
kubectl apply -f timecheck/
kubectl logs -l app=timecheck --all-containers -n kiamol-ch13-dev --tail 1
kubectl logs -l app=timecheck --all-containers -n kiamol-ch13-test --tail 1
kubectl apply -f sleep.yaml
kubectl exec -it deployments/sleep -- sh
cd /var/log/containers/
cat timecheck-54b89495c4-x4dv4_kiamol-ch13-test_logger-*
exit

kubectl get pod -o wide

kubectl apply -f fluentbit/
kubectl get po -n kiamol-ch13-logging -o wide
kubectl logs -l app=fluent-bit -n kiamol-ch13-logging --tail 2
kubectl get daemonsets.apps  -n kiamol-ch13-logging

kubectl apply -f fluentbit/update/fluentbit-config-match.yaml
kubectl rollout restart ds/fluent-bit -n kiamol-ch13-logging
kubectl logs -l app=fluent-bit -n kiamol-ch13-logging --tail 1

- elasticsearch & kibana
kubectl apply -f elasticsearch
kubectl get pod -l app=elasticsearch -n kiamol-ch13-logging
kubectl patch svc kibana -p '{"spec": {"externalIPs": ["172.16.0.150"]}}' -n kiamol-ch13-logging
kubectl apply -f fluentbit/update/fluentbit-config-elasticsearch.yaml
kubectl rollout restart ds/fluent-bit -n kiamol-ch13-logging
kubectl apply -f numbers/
kubectl patch svc numbers-api-proxy -p '{"spec": {"externalIPs": ["172.16.0.150"]}}' -n kiamol-ch13-test
curl http://172.16.0.150:8080/rng

kubernetes.labels.app:numbers-api AND log:dc4e0c87-b7bb-4f28-81d8-94726fdf4232

t log	   	2024-05-14T23:25:23.070311741+09:00 stdout F <4>Numbers.Api.Controllers.RngController[0] Unhealthy! Failure ID: dc4e0c87-b7bb-4f28-81d8-94726fdf4232

--- Kubernetes 프로메테우스, 그라파나
helm repo add stable https://charts.helm.sh/stable
helm search repo
helm repo update
helm install stable/mysql --generate-name
helm list
helm uninstall mysql-1672897024
helm list
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm search repo prometheus
helm install prometheus-community/kube-prometheus-stack --generate-name
kubectl edit service/kube-prometheus-stack-1672897171-grafana NodePort로 변경
kubectl get secret/kube-prometheus-stack-1688083950-grafana -o jsonpath="{.data.admin-password}" | base64 --decode;echo
admin/prom-operator
 kubectl edit svc kube-prometheus-stack-1688-prometheus NodePort로 변경

### 2. 쿠머네티스 클러스터 구성 
### 3. 파드와 디플로이먼트 컨테이너 실행 
### 4. 네트워크 서비스 파드 연결 
### 5. 컨피그맵과 시크릿으로 애플리케이션 설정 
### 6. 볼륨, 마운트, 클레임을 활용한 영구 볼륨 
